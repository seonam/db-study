# 인덱스 튜닝
## 테이블 액세스 최소화

반복해서 말했듯이 SQL 튜닝은 랜덤IO 와의 전쟁이다.

### 테이블 랜덤 액세스

SQL 이 참조하는 컬럼을 인덱스가 모두 포함하는게 아니면 인덱스 스캔 후 반드시 테이블을 액세스 한다. "TABLE ACCESS BY INDEX ROWID" 라 표시된 부분이 여기에 해당한다.

![](../images/btree_01.png)

인덱스를 스캔하는 이유는 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빨리 찾고 거기서 테이블 레코드를 찾아가기 위한 주소값인 ROWID 를 얻기 위해서다. 여기서 말하는 ROWID 는 논리적 주소다.

보통 프로그래밍 언어에서 포인터는 메모리 주소값을 담는 변수이다. 메모리에 있는 데이터를 찾아가는 데 있어 포인터로 접근하는 것보다 빠른 방법은 없으며 비용은 O(0)에 가깝다. 물리적으로 직접 연결된 구조와 다름없다.

이 포인터를 생각하여 ROWID 를 이해하면 안된다. 이는 디스크 상에서 테이블 레코드를 찾아가기 위한 위치 정보를 담을 뿐이다.

#### 메인 메모리 DB 와 비교

메인 메모리 DB 는 데이터를 모두 메모리에 로드하고 메모리를 통해서만 IO 를 수행하는 DB 다. 보통 잘 튜닝된 OLTP 성 데이터베이스 시스템은 버퍼 캐시 히트율이 99% 이상이다. 디스크를 경유하지 않고 대부분 메모리에서 읽는다는 의미이다. 그럼에도 메인 메모리 DB 만큼 빠르진 않다.

메인 메모리 DB 는 인스턴스를 기동하면 디스크에 저장된 데이터를 버퍼캐시로 로딩하고 인덱스를 생성한다. 이 때, 인덱스는 오라클처럼 디스크 상의 주소정보를 갖는게 아닌, 메모리상의 주소정보인 포인터를 갖게되며, 오라클보다 훨씬 빠르다.

오라클은 테이블 블록이 수시로 버퍼캐시에서 밀려낫다가 다시 캐싱되며, 그때마다 다른 공간에 캐싱되므로 인덱스에서 포인터로 직접 연결할 수 없는 구조다. 메모리 주소 정보(포인터)가 아닌 디스크 주소 정보를 이용해 해시 알고리즘으로 버퍼 블록을 찾는다.


#### IO 메커니즘 복습
DBA(데이터파일번호 + 블록번호)는 디스크 상에서 블록을 찾기 위한 주소 정보다. 디스크에서 블록을 읽기 전 버퍼 캐시를 읽는다. 읽고자 하는 DBA 를 해시 함수에 입력해서 해시 체인을 찾고 거기서 버퍼 헤더를 찾는다.

캐시에 적재할 때와 읽을 때 같은 해시 함수를 사용하므로 버퍼 헤더는 항상 같은 해시 체인에 연결된다. 반면, 실제 데이터가 담긴 버퍼 블록은 매번 다른 위치에 캐싱되는데, 그 메모리 주소값을 버퍼 헤더가 가지고 있다. 즉, 해싱 알고리즘으로 버퍼 헤더를 찾고, 거기서 얻은 포인터로 버퍼 블록을 찾아간다.

인덱스로 테이블 블록을 접근할 땐 리프에서 읽을 ROWID 를 분해해 DBA 정보를 얻고, 테이블 풀스캔일 땐 익스텐트 맵을 통해 읽을 블록들의 DBA 정보를 얻는다.

![img_1.png](../images/dba01.png)

모든 데이터가 버퍼 캐시에 캐싱되어 있어도 테이블 레코드를 찾기 위해 매번 DBA 해싱과 래치 획득 과정을 반복해야 한다. 동시 액세스가 심할 땐 캐시버퍼 체인 래치와 버퍼 락에 대한 경합도 발생한다. 이처럼 인덱스 ROWID 를 이용한 테이블 앵ㄱ세스는 생각보다 고비용이다.


### 인덱스 클러스터링 팩터 (CF, 군집성 계수)
CF 는 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도를 의미한다. CF 가 좋은 컬럼에 생성한 인덱스는 검색 효율이 매우 좋다. 예를 들어, 거주지역 = 제주 에 해당하는 고객 데이터가 물리적으로 근접해있으면 흩어진것보다 데이터 찾는 속도가 빠르다.

CF 가 좋은 컬럼에 생성한 인덱스는 검색 효율이 좋다고 했는데, 이는 테이블 액세스량에 비해 블록 IO 가 적게 발생함을 의미한다. 앞서 인덱스 레코드마다 테이블 레코드를 건건이 블록 단위로 IO 한하면 CF 에 의한 블록 IO 발생량은 차이가 없어야 한다. 왜 이런 차이가 발생할까?

인덱스 ROWID 로 테이블을 접근할 떄 오라클은 래치 획득과 해시 체인 스캔 과정을 거쳐 어렵게 찾아간 테이블 블록에 대한 포인터를 바로 해제하지 않고 일단 유지하는데, 이를 버퍼 피닝이라 한다.

이 상태에서 다음 인덱스 레코드를 읽었는데, 직전과 같은 테이블 블록을 가리키면 래치 획득과 해시 체인 스캔 과정을 생략하고 바로 테이블 블록을 읽어 논리적인 블록 IO 과정을 생략할 수 있다. 즉, 같은 테이블 블록을 여러번 읽지 않아도 된다. 이 때문에 인덱스 레코드 정렬 순서와 테이블 레코드 정렬순서가 어느정도 일치하는 CF 가 좋은 컬럼이 성능이 좋다.


### 인덱스 손익분기점

인덱스의 테이블 접근 비용은 고비용이므로 읽어야 할 데이터가 일정량을 넘으면 테이블 풀 스캔보다 느리게 된다. 테이블 풀 스캔은 1000만건중 한건을 조회하든 10만건을 조회하든 성능이 일정하다. 

인덱스를 이용해 테이블에 접근할 땐 1000만건중 몇건을 추출하냐에 따라 성능이 크게 달라진다. 이유를 정리하면 다음과 같다.

- 테이블 풀 스캔: 시퀀셜 액세스, multiblock IO
- 인덱스 ROWID 를 이용한 테이블 접근: 랜덤 액세스, Single Block IO 

이에 의해 인덱스 손익분기점은 보통 5~20%에서 결정된다. 인덱스 CF 가 나쁘면 같은 테이블 블록을 여러번 반복해서 접근해야 하므로 논리적 IO 횟수가 늘고 물리적 IO 횟수도 늘게된다. 이 때문에 CF 가 나쁘면 손익분기는 5%미만에서 결정되며 BCHR 이 매우 안좋을 때는 1% 미만으로 낮아진다. 반대로 인위적으로 전체 데이터를 인덱스 컬럼 순으로 정렬해서 재입력해 CF 가 아주 좋을 땐 90%까지 올라가기도 한다.   

---
다만 위에서 언급한 5~20% 는 만아봐야 100만 이내의 테이블에 적용되는 수치다. 1000만건 수준으로 큰 테이블은 더 낮아진다.

예를 들어, 10만건 테이블에서 10%는 만건으로, 이정도면 버퍼캐시에서 데이터를 찾을 가능성이 있고, 인덱스 컬럼 기준으로 값이 같은 테이블 레코드가 근처에 모여 있을 가능성도 있다.

반면 1000만건일 경우 10%면 100만건으로, 버퍼캐시에서 찾을 가능성이 작아져 성능이 훨씬 더 느려진다. 버퍼캐시에 할당하는 메모리 크기가 점점 커지긴하지만, 요즘 기준으로 보통 수백만개 블록을 캐싱하는 수준이다. 특정 테이블을 인덱스로 100만건 이상 접근하면 캐시 히트율은 극히 낮아질 수 밖에 없다.

따라서 만건만 넘어도 시퀀셜 액세스와 멀티블록 IO 인 테이블 풀 스캔이 빠를 수 있다.

---

#### 온라인 vs 배치 튜닝

온라인 프로그램은 보통 소량 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는게 중요하며 조인도 대부분 NL 이다. NL 은 인덱스를 이용해 조인한다.

배치 프로그램은 항상 전체범위 처리 기준으로 튜닝해야한다. 즉, 처리대상 집합 중 일부를 빠르게 처리하는게 아닌, 전체를 빠르게 처리하는걸 목표로 해야 한다. 대량 데이터를 빠르게 처리하려면 인덱스와 NL 조인보단 풀스캔과 해시조인이 유리하다.

대량 배치에선 인덱스보다 풀스캔이 효율적이지만 초대량 테이블에서 풀스캔은 시스템에 부담도 주고 오래 기다려야 한다. 따라서 배치에서는 파티션 활용 전략이 매우 중요한 튜닝 요소이고 병렬처리까지 더할 수 있으면 좋다. 

**테이블을 파티셔닝 하는건 인덱스 성능보다 풀스캔을 빠르게 처리하기 위해서라는걸 기억하자.** 

### 인덱스 컬럼 추가
보통 테이블 접근을 줄이기 위해 가장 일반적으로 사용하는 튜닝 방식은 인덱스에 컬럼을 추가하는 것이다. (DEPTNO, JOB) 으로 구성한 인덱스가 있을 때 아래를 수행하면 deptno = 30 에 해당하는 모든 사원에 대해 테이블에 접근해야 한다.

```sql
select *
from emp
where deptno = 30
and   sal >= 2000
```

(DEPTNO, SAL) 로 인덱스를 변경하면 좋겟지만 운영에서는 해당 인덱스를 사용하고 있을 수 있어서 변경하기 어렵다. 새로 만든다면 한 테이블에 인덱스가 수십개씩 달려 인덱스 관리 비용이 증가함은 물론이고 DML 부하로 인해 트랜잭션 성능 저하가 생길 수 있다.

이럴 땐, (DEPTNO, JOB, SAL) 으로 SAL 컬럼만 추가하는 것으로 큰 효과를 얻을 수 있다. 인덱스 스캔량은 줄진 않지만 sal 을 인덱스로 확인할 수 있으므로 테이블 랜덤 액세스 횟수를 줄일 수 있기 때문이다.

### 인덱스만 읽고 처리
테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 위 처럼 인덱스에 컬럼을 추가하는 걸로는 성능 향상을 볼 수 없다.

아래 쿼리에서 (부서번호) 인덱스를 사용하면 인덱스에서 부서번호 LIKE 조건에 해당하는 데이터를 찾고 테이블을 접근한 후에 버리는 데이터가 하나도 없어 비효율은 없다. 비효율이 없어도 인덱스 스캔 과정에서 얻은 데이터가 많으면 그만큼 테이블 랜덤 액세스가 많아 성능이 느릴 수 밖에 없다.
```sql
select 부서번호, sum(수량)
from 판매집계
where 부서번호 like '12%'
group by 부서번호
```

쿼리나 인덱스 문제가 아니라 절대량이 많은거라 어쩔 수 없이 느린대로 사용해야 한다.

**다만, 위 처럼 쿼리에 컬럼이 많지 않다면 수량 컬럼만 인덱스에 추가하면 커버드 인덱스가 되어 테이블 액세스를 제거할 수 있어 성능을 획기적으로 개선할 수 있다.**

### 인덱스 구조 테이블

램덤 액세스가 아예 발생하지 않도록 테이블을 인덱스 구조로 생성하는 IOT(Index-Organized Table)이 있다.

테이블을 찾아가기 위한 ROWID 를 갖는 일반 인덱스와 달리 IOT 는 그 자리에 테이블 데이터를 갖는다. 즉, 테이블 블록에 있어야 할 데이터를 인덱스 리프 블록에 모두 저장하고 있다. 즉, 인덱스 리프 블록이 곧 데이터 블록이다.

테이블을 인덱스 구조로 만드는 구문은 아래와 같다.

```sql
create table index_org_t (a number, b varchar(10), constraint index_org_t_pk primary key(a))
organization index;
```

참고로 일반 테이블은 힙 구조 테이블이라 한다. 테이블 생성할 때 대개 생략하지만 아래처럼 organization 옵션을 명시할 수 있다.

```sql
create table index_org_t (a number, b varchar(10), constraint index_org_t_pk primary key(a))
organization heap;
```

일반 힙 구조 테이블에 데이터를 입력할 땐 랜덤 방식으로, Freelist 로부터 할당 받은 블록에 정해진 순서없이 데이터를 입력한다. 반면 IOT 는 인덱스 구조 테이블이므로 정렬 상태를 유지하며 데이터를 입력한다.

IOT 는 인위적으로 CF 를 좋게 만드는 방법 중 하나다. 같은 값을 가진 레코드가 항상 정렬된 상태이므로 랜덤 액세스가 아닌 시퀀셜 방식으로 데이터를 접근하여 between 이나 부등호 조건으로 넓은 범위를 읽을 때 유리하다.

데이터 입력과 조회 패턴이 다른 테이블에서도 유용하다. 예를 들어, 영업사원들의 일별 실적을 집계하는 테이블은 실적 등록은 일자별로 진행되지만 실적 조회는 주로 사원별로 이루어진다. 영업사원 100명, 한 블록에 100개의 레코드가 담겨 매일 한 블록씩 담긴다 하자.

```sql
select substr(일자, 1, 6) 월도,
       sum(판매금액) 총판매금액,
       avg(판매금액) 평균판매금액
from 영업실적
where 사번 = '123'
and   일자 between '20180101' and '20181231'
group by substr(일자, 1, 6)
```
위 쿼리에 인덱스를 이용하면 사원마다 랜덤 액세스 방식으로 365개 테이블 블록을 읽어야 하는데, CF 가 매우 안좋으므로 조회 건수만큼 블록IO 가 발생한다.

입력과 조회패턴이 다를 때 아래처럼 사번이 첫번째 정렬 기준이 되도록 IOT 를 구성하면 한 블록에 100개 레코드가 담기므로 네개 블록만 읽고 처리할 수 있다.

```sql
create table 영업실적(사번 varchar2(5), 일자 varchar2(8), ... primary eky(사번, 일자)) organization index;
```


### 클러스터 테이블

## 부분범위 처리 활용
### 부분범위 처리
DBMS 가 클라이언트에게 데이터를 전송할 때 일정량씩 나누어 전송한다. 전체 결과집합 중 아직 전송하지 않은 분량이 많이 있어도 서버 프로세스는 클라이언트로부터 추가 fetch call 을 받기 전까지 기다린다.

OLTP 에서 대량 데이터를 빠르게 다룰 수 있는 원리가 여기에 있다.

```kotlin
val stmt = con.createStatement()
val rs: ResultSet = stmt.executeQuery("select name from big_table")

(0..100).forEach {
    if(rs.next()) println(rs.getString(1))
}

rs.close()
stmt.close()
```

위 쿼리 조회 결과가 1억건이라도 빠르게 결과를 볼 수 있는 이유는 먼저 읽은 데이터를 일정량 전송하고 멈추기 때문이다. 서버 프로세스는 데이터 전송후에 CPU 를 os 에 반환하고 큐에서 기다리다, 다음 fetch call 을 받으면 큐에서 나와 다음 데이터를 일정량 읽어 전송하고 대기한다.

이렇게 전체 결과집합을 쉼없이 연속적으로 전송하지 않고 사용자가 fetch call 을 할때 일정량씩 나누어 전송하는걸 부분범위 처리라 한다.

이 단위는 array size 로 자바는 기본이 10이며, Statement 객체 setFetchSize 로 설정할 수 있다. 정리하면 아래와 같이 동작한다.

1. 최초 rs.next() 호출 시 fetch call 로 db 서버로부터 전송받은 데이터 10건을 클라이언트 캐시에 저장한다.
2. 이후 rs.next() 호출할 때 fetch call 을 발생시키지 않고 캐시에서 데이터를 읽는다.
3. 캐시에 저장한 데이터를 모두 소진한 상태에서 rs.next() 호출 시 추가 fetch call 을 통해 10건만 받는다.
4. 데이터를 다 읽을 때 까지 2~3을 반복한다.

즉, 쿼리 결과집합이 1억건이라도 버퍼캐시에 모두 적재하고 사용자에게 전송하는게 아닌, array size 만큼만 적재하게 된다.

다만 아래처럼 order by 가 있으면 서버는 모든 데이터를 다 읽어 created 순으로 정렬을 마치고 데이터를 전송하므로 전체범위처리가 된다. Sort area 와 temp 테이블스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에 데이터를 전송한다.

```kotlin 
val stmt = con.createStatement()
val rs: ResultSet = stmt.executeQuery("select name from big_table order by created")
```

**만약 created 컬럼이 선두인 인덱스가 있으면 항상 정렬되어 있는 인덱스가 있으므로, 전체 데이터를 정령하지 않고도 정렬된 상태의 결과집합을 바로 전송할 수 있으므로 부분범위 처리가 가능하다.**

참고로 array size 를 용도에 맞게 설정해야 한다. 만약 대량 데이터를 파일로 내려받는다면 어차피 데이터를 모두 전송해야 하므로 Array size 를 크게 설정하여 fetch call 을 줄이는게 좋다. 반대로, 몇건만 조회한다면 작게 설정하는게 유리하다.

### OLTP 환경에서 부분범위 처리에 의한 성능개선 원리

OLTP 라고 항상 소량 데이터만 조회하는 건 아니다. 수만건을 조회하는 경우도 있는데, 인덱스를 이용해도 랜덤 액세스로 인해 성능을 내기 어렵다. 

다행히 OTLP 에서 쿼리 결과 집합이 많을 때 사용자가 모든 데이터를 일일이 다 확인하진 않는다. 은행계좌 입출금 조회, 뉴스 조회 등 특정한 정렬 순서로 상위 일부 데이터만 확인한다.  이 때 항상 정렬 상태를 유지하는 인덱스를 이용하면 정렬 작업을 생략하고 앞쪽 일부 데이터를 아주 빠르게 보여줄 수 있다.

인덱스와 부분범위 처리 원리를 잘 이용하면 OLTP 환경에서 극적인 성능개선 효과를 얻을 수 있는 원리가 여기에 있다.

```sql
select 게시글ID
from 게시판
where 게시판구분코드 = 'A'
order by 등록일시 desc
```

위에서 (게시판구분코드, 등록일시) 로 인덱스 선두 컬럼을 구성하지 않으면 소트 연산을 생략할 수 없다. A 조건을 만족하는 모든 레코드를 인덱스에서 읽어야하고 그만큼 많은 테이블 랜덤 액세스가 발생한다.
모든 데이터를 다 읽고 등록일시 역순으로 정렬을 마치고 출력을 시작하므로 OLTP 에서 요구되는 빠른 응답을 내기 어렵다.

**(게시판구분코드, 등록일시) 로 구성된 인덱스가 있으면 소트 연산이 생략되고, 부분범위 처리로 인해 전체 데이터에 대해 테이블 랜덤 액세스를 하지 않아도 되어 성능이 향상된다.**


### 배치 IO
디스크 랜덤 IO 성능을 개선하기 위해 많은 업체가 노력하는데, 최근 가장 좋은 개선은 배치 IO 다. 이는 읽는 블록마다 건건이 IO call 을 발생시키는 비효율을 줄이기 위한 기능이다. 인덱스를 이용해 테이블을 접근하다 버퍼 캐시에서 블록을 찾지 못하며 일반적으로 디스크 블록을 바로 읽는데,
이 기능이 작동하면 테이블 블록에 대한 디스크 IO call 을 미뤗다가 읽을 블록이 어느정도 쌓이면 한번에 처리한다.

12c 부터는 인덱스 ROWID 로 테이블을 접근하는 어떤 부분에서든 이 기능이 작동할 수 있다.

#### 데이터 정렬 이슈
배치 IO 기능이 작동하면 인덱스를 이용해서 출력하는 데이터 정렬 순서가 매번 다를 수 있다. 버퍼캐시 히트율이 100%라서 테이블 블록을 모두 버퍼 캐시에서 찾을때는 기존처럼 인덱스 키값 순으로 데이터가 출력되지만, 아닐 때 배치 IO 가 작동한다면 데이터 출력 순서가 인덱스 정렬 순과 다를 수 있다.

옵티마이저는 인덱스로 소트 연산을 생략할 수 없거나 order by 가 없으면 램덤 IO 성능을 향상하는 배치 IO 를 기본적으로 선택한다.

다만, 시스템 레벨에서 이를 비활성화하는 경우도 있다. SQL 에 order by 가 없으면 결과집합의 정렬 순서를 보장할 필요가 없으므로 옵티마이저가 배치 IO 를 선택해 출력된 결과집합의 정렬 순서가 매번 다를 수 있다. 이 경우, 필요한 order by 를 생략한 SQL 패턴에서 문제가 발생한다.

과거에는 인덱스를 이용하면 결과집합이 자동으로 인덱스 키값 순으로 정렬되므로 order by 를 생략하는 패턴을 사용하곤 했는데, 이런 경우 배치 IO 기능을 사용할 수 없다. 이런 경우 이런 패턴을 개선해야 되지 배치 IO 기능을 비활성화하는건 추천하지 않는다.  


# 참고
- https://codeforest-document.tistory.com/22